{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30c95672",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "import torch\n",
    "from torch import nn\n",
    "import spacy\n",
    "import random\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchtext.data.utils import get_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "299d32df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 2.5351,  0.7386,  0.9047,  0.6718,  1.8967],\n",
       "          [-0.6330,  0.6107,  1.7674,  1.1559, -0.6745],\n",
       "          [-0.1930,  0.3196,  1.6610, -0.2573, -1.1351],\n",
       "          [ 1.7515,  1.2135,  0.1067, -0.5647, -0.2714]],\n",
       " \n",
       "         [[ 0.5914,  1.2536, -0.0083,  1.7683,  0.4249],\n",
       "          [ 0.2459,  0.8544,  0.1151,  1.4737,  0.9920],\n",
       "          [ 0.7062,  0.1403, -0.3241,  3.4067,  0.7415],\n",
       "          [ 0.5486, -0.2074,  1.5844,  0.5252,  0.6802]],\n",
       " \n",
       "         [[-0.8402,  0.2314,  0.7635, -0.9660, -0.0707],\n",
       "          [ 2.0927,  0.9093,  1.1700,  2.1372,  0.8773],\n",
       "          [-0.6008,  2.9211,  1.0879,  1.1569,  0.5145],\n",
       "          [ 2.4891,  1.3333, -0.1935, -1.3532, -0.0552]]]),\n",
       " tensor([[[0, 0, 0, 0, 1],\n",
       "          [0, 1, 0, 0, 1],\n",
       "          [1, 0, 0, 0, 0],\n",
       "          [1, 1, 0, 1, 0]],\n",
       " \n",
       "         [[1, 0, 1, 0, 0],\n",
       "          [0, 1, 1, 0, 1],\n",
       "          [0, 1, 1, 1, 0],\n",
       "          [0, 1, 0, 0, 1]],\n",
       " \n",
       "         [[1, 0, 1, 1, 0],\n",
       "          [0, 0, 0, 1, 0],\n",
       "          [0, 1, 1, 1, 0],\n",
       "          [0, 1, 0, 1, 0]]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(2,3,4,5)\n",
    "v, i = torch.max(a, dim=0)\n",
    "v, i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4591529c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from collections import Counter\n",
    "from torchtext.datasets import Multi30k\n",
    "# from torchtext.datasets import IMDB\n",
    "from torchtext.vocab import vocab\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "# from torchtext.data import get_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fe893ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.17.2+cpu'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchtext.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5efa88c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.',\n",
       " 'Two young, White males are outside near many bushes.')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_iter = Multi30k(split=('train'))\n",
    "next(iter(train_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a891bf4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pouya\\jupyter projects\\ml_venv\\lib\\site-packages\\torch\\utils\\data\\datapipes\\iter\\combining.py:337: UserWarning: Some child DataPipes are not exhausted when __iter__ is called. We are resetting the buffer and each child DataPipe will read from the start again.\n",
      "  warnings.warn(\"Some child DataPipes are not exhausted when __iter__ is called. We are resetting \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "29001"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(train_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26bca061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.de.German at 0x19c9adb6620>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_eng = spacy.load(\"en_core_web_sm\")\n",
    "spacy_ger = spacy.load(\"de_core_news_sm\")\n",
    "spacy_ger "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b744f0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_tokenizer = get_tokenizer('basic_english')\n",
    "spacy_eng = spacy.load(\"en_core_web_sm\")\n",
    "spacy_ger = spacy.load(\"de_core_news_sm\")\n",
    "ger_tokenizer = lambda x: [tok.text for tok in spacy_ger.tokenizer(x)]\n",
    "# spacy_eng_tokenizer = lambda x: [tok.text for tok in spacy_eng.tokenizer(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db1dcfa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Zwei',\n",
       " 'junge',\n",
       " 'weiße',\n",
       " 'Männer',\n",
       " 'sind',\n",
       " 'im',\n",
       " 'Freien',\n",
       " 'in',\n",
       " 'der',\n",
       " 'Nähe',\n",
       " 'vieler',\n",
       " 'Büsche',\n",
       " '.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ger_tokenizer('Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "746bc5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_train_eng = Counter()\n",
    "for src, trg in train_iter:\n",
    "    counter_train_eng.update(eng_tokenizer(trg))\n",
    "\n",
    "counter_train_ger = Counter()\n",
    "for src, trg in train_iter:\n",
    "    counter_train_ger.update(ger_tokenizer(src))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58092da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the new vocab is 5921\n",
      "The index of <sos> is 1\n",
      "The token at index 2 is young\n"
     ]
    }
   ],
   "source": [
    "eng = vocab(counter_train_eng, min_freq=2, specials=['<pad>', '<sos>', '<eos>', '<unk>'])\n",
    "ger = vocab(counter_train_ger, min_freq=2, specials=['<pad>', '<sos>', '<eos>', '<unk>'])\n",
    "\n",
    "print(\"The length of the new vocab is\", len(eng))\n",
    "new_stoi = eng.get_stoi()\n",
    "print(\"The index of <sos> is\", new_stoi['<sos>'])\n",
    "new_itos = eng.get_itos()\n",
    "print(\"The token at index 2 is\", new_itos[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "142f7e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eng.set_default_index(eng['<unk>'])\n",
    "# eng['<unk>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7932ac45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: Two young, White males are outside near many bushes.\n",
      "output of text_transform: [1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 2]\n"
     ]
    }
   ],
   "source": [
    "text_transform_eng = lambda x: [eng[\"<sos>\"]] + [eng[token] for token in eng_tokenizer(x)] + [eng['<eos>']]\n",
    "text_transform_ger = lambda x: [ger[\"<sos>\"]] + [ger[token] for token in ger_tokenizer(x)] + [ger['<eos>']]\n",
    "print(f\"input: {next(iter(train_iter))[1]}\")\n",
    "print(f\"output of text_transform: {text_transform_eng(next(iter(train_iter))[1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ad5405",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91945553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def yield_tokens(examples):\n",
    "#     for example in examples:\n",
    "#         tokens = tokenizer(example)\n",
    "# #         print('tokens:', tokens)\n",
    "#         yield tokens\n",
    "\n",
    "# text_list = [\"hello world how are you doing\",\n",
    "#         \"hi, world what is up and how are you doing world?\"]\n",
    "# list(yield_tokens(text_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b878fdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# token_generator = yield_tokens(text_list)\n",
    "# vocab = build_vocab_from_iterator(token_generator, min_freq=1, specials=['<pad>', '<sos>', '<eos>', '<unk>'],\\\n",
    "#                                  special_first=False)\n",
    "# {k:v for k,v in sorted(vocab.get_stoi().items(), key=lambda x:x[1])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8d19cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab.set_default_index(vocab['<unk>'])\n",
    "# vocab.get_stoi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eeb03344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab['world']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aff4eebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(yield_tokens(text_list))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01eee763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab.lookup_token(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10575a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab.lookup_indices(list(yield_tokens(text_list))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2464a57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c3a716b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee24ccb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, embedding_size, n_layers, p):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = nn.LSTM(embedding_size, hidden_size, n_layers, dropout=p)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        output, (hidden, cell) = self.rnn(embedding)\n",
    "        return hidden, cell\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d18c869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder(\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (embedding): Embedding(6, 500)\n",
       "  (rnn): LSTM(500, 400, num_layers=3, dropout=0.5)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = Encoder(6, 400, 500, 3, 0.5)\n",
    "encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "026a4032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2, 400]), torch.Size([3, 2, 400]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = torch.randint(0,2,(6,2))\n",
    "hidden, cell = encoder(inp)\n",
    "hidden.shape, cell.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ff7270c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, output_size, n_layers, p):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_size, n_layers)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x, hidden, cell):\n",
    "        #we are sending one word rather than a sentence: N -> (1, N) for (sequence lenght, batch size)\n",
    "        x = x.unsqueeze(0)\n",
    "        x = self.dropout(self.embedding(x))\n",
    "        output, (hidden, cell) = self.lstm(x, (hidden, cell))\n",
    "        #(seq length, N, output_size)\n",
    "        predictions = self.fc(output)\n",
    "        \n",
    "        #(N, output_size)\n",
    "        predictions = predictions.squeeze(0)\n",
    "        \n",
    "        return predictions, hidden, cell\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e2704f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder(10, 64, 128, 50, 1, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bdf60f97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 50, 128])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randint(0,5, (1, 50)).reshape(50)\n",
    "h = torch.zeros(1, 50, 128)\n",
    "c = torch.zeros(1, 50, 128)\n",
    "decoder(x, h, c)[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "31dd6012",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, source, target, teacher_force_ratio=0.5):\n",
    "        batch_size = source.shape[1]\n",
    "        target_len = target.shape[0]\n",
    "        target_vocab_size = len(english.vocab)  ###debug\n",
    "        \n",
    "        outputs = torch.zeros(target_len, batch_size, target_vocab_size)\n",
    "        \n",
    "        hidden, cell = self.encoder(source)\n",
    "        \n",
    "        x = target[0]\n",
    "        for i in range(target_len):\n",
    "            output , hidden, cell = self.decoder(x, hidden, cell)\n",
    "            \n",
    "            outputs[i] = output\n",
    "            \n",
    "            best_guess = output.argmax(dim=1) \n",
    "            \n",
    "        x = target[i] if random.random() < teacher_force_ratio else best_guess\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dfeba9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else \"cpu\"\n",
    "lr = 0.001\n",
    "epochs = 100\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5b97257d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size_encoder = 1000  ##debug len(vocab)\n",
    "input_size_decoder = 1000  ##debug len(vocab)\n",
    "output_size = 100\n",
    "encoder_embedding_size = 300\n",
    "decoder_embedding_size = 300\n",
    "hidden_size = 1024\n",
    "num_layers = 2\n",
    "enc_dropout = 0.5\n",
    "dec_dropout = 0.5\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "97206704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.',\n",
       "  'Two young, White males are outside near many bushes.'),\n",
       " ('Mehrere Männer mit Schutzhelmen bedienen ein Antriebsradsystem.',\n",
       "  'Several men in hard hats are operating a giant pulley system.'),\n",
       " ('Ein kleines Mädchen klettert in ein Spielhaus aus Holz.',\n",
       "  'A little girl climbing into a wooden playhouse.')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_iter)[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "beb40164",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    eng_list, ger_list = [], []\n",
    "    for ger, eng in batch:\n",
    "        processed_eng = torch.tensor(text_transform_eng(eng))\n",
    "        eng_list.append(processed_eng)\n",
    "        processed_ger = torch.tensor(text_transform_ger(ger))                            \n",
    "        ger_list.append(processed_ger)        \n",
    "    return pad_sequence(ger_list, padding_value=3.0), pad_sequence(eng_list, padding_value=3.0)\n",
    "\n",
    "train_dataloader = DataLoader(list(train_iter), batch_size=batch_size, shuffle=True, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ce6b4f60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(454, torch.utils.data.dataloader.DataLoader)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader),type(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a06e8a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Ein Mann in grün hält eine Gitarre, während der andere Mann sein Hemd ansieht.',\n",
       " 'A man in green holds a guitar while the other man observes his shirt.')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_list = list(train_iter)\n",
    "train_list[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8adce7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e50b5ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_ger = [(i, len(ger_tokenizer(s[0]))) for i, s in enumerate(train_list)]\n",
    "\n",
    "def batch_sampler():\n",
    "    indices_eng = [(i, len(ger_tokenizer(s[1]))) for i, s in enumerate(train_list)]\n",
    "    random.shuffle(indices_eng)\n",
    "    pooled_indices = []\n",
    "    for i in range(0, len(indices_eng), batch_size*50):\n",
    "        pooled_indices.extend(sorted(indices_eng[i: i+batch_size*50], key=lambda x: x[1]))\n",
    "\n",
    "    pooled_indices = [x[0] for x in pooled_indices]\n",
    "\n",
    "    for i in range(0, len(pooled_indices), batch_size):\n",
    "        yield pooled_indices[i:i+batch_size]\n",
    "\n",
    "bucket_dataloader = DataLoader(train_list, batch_sampler=batch_sampler(),\n",
    "                               collate_fn=collate_batch)\n",
    "\n",
    "# next(iter(bucket_dataloader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25263ce9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "df359663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 100, 1024])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = Encoder(input_size_encoder, hidden_size, encoder_embedding_size, num_layers, enc_dropout)\n",
    "x = torch.randint(1,5, (10, 100))\n",
    "encoder(x)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "55159cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 'result1', 1: 'result2'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict([\n",
    "    (2,'result1'),\n",
    "    (1, 'result2')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dbd585cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5738.7],\n",
       "       [5721.9],\n",
       "       [5811. ],\n",
       "       [5797.9],\n",
       "       [5802. ],\n",
       "       [5782.1],\n",
       "       [5647.5],\n",
       "       [5912.7],\n",
       "       [5757.8],\n",
       "       [5685.1]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "lst = [[random.randint(4000,6000) for i in range(50)] for i in range(10)]\n",
    "np.percentile(lst, 90,axis=1 ,keepdims=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
